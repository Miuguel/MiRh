Extraia features visuais das imagens “Questionario-4-Bricks1.jpg”, “Questionario-4-Bricks2.jpg”, “Questionario-4-Building1.jpg” “Questionario-4-Building2.jpg” disponibilizadas junto a este questionário no Google Classroom. Além dessas, inclua pelo menos um par de imagens próprias capturadas por você. As features extraídas devem ser do tipo SIFT e features coletadas na saída de camadas de uma rede VGG-16 pré-treinada para o problema de classificação de imagens. No caso da rede VGG-16, utilize a metodologia descrita neste artigo:  Multi-Temporal_Remote_Sensing_Image_Registration_Using_Deep_Convolutional_Features.pdf, mas adapte-a para camadas e campos receptivos que façam sentido para o problema de correspondência dos casos considerados neste exercício. Uma vez extraídas as features de cada tipo em cada par de imagens, verifique a qualidade das features para o problema de registro de imagens. É permitido o uso de SIFT implementado por terceiros no OpenCV ou em bibliotecas similares (devido à patente, SIFT deve ser compilado à parte no OpenCV). Também é permitido o uso de implementações de matching de features disponíveis nessas bibliotecas (por exemplo, cv2.BFMatcher e cv2.FlannBasedMatcher no OpenCV). Os resultados de registro devem ser apresentados colocando as imagens do par lado a lado e desenhando segmentos de reta indicando o matching obtido (veja, por exemplo, os resultados disponíveis neste tutorial OpenCV_ Feature Matching.pdf ). Envie como resultado um arquivo ZIP contendo tanto o código fonte do programa produzido quanto as imagens resultantes do processamento, salvas como PNG. Fique atento à resolução das imagens dadas e a resolução da rede VGG-16. Será preciso redimensionar as imagens de entrada antes da extração de features.

Comente os resultados obtidos na questão anterior. Disserte sobre a quantidade de features obtidas por cada um dos processos de extração (SIFT vs. VGG-16 features) e a qualidade do matching.